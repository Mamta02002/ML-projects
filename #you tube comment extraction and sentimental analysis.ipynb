{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ec43f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install youtube-comment-scraper-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d81a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DataKund...\n",
      "Youtube links: https://youtu.be/jtn-hRJjl68\n",
      "Output name: comments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  66%|█████████████████████████████████████████████                       | 132.6/200 [00:26<00:22,  3.03it/s]\n",
      "Progress:  69%|██████████████████████████████████████████████▉                     | 138.0/200 [00:32<00:33,  1.84it/s]\u001b[A\n",
      "Progress:   8%|█████▎                                                               | 15.4/200 [00:04<00:48,  3.82it/s]\u001b[A\n",
      "Progress:  84%|█████████████████████████████████████████████████████████▍          | 168.8/200 [00:34<00:06,  4.65it/s]\u001b[A\n",
      "Progress: 210.60000000000002it [00:40,  5.32it/s]                                                                      \u001b[A\n",
      "Progress: 216.20000000000002it [00:42,  4.72it/s]                                   | 88.0/200 [00:12<00:16,  6.68it/s]\u001b[A\n",
      "Progress: 220.60000000000002it [00:44,  4.11it/s]                                   | 93.6/200 [00:14<00:19,  5.59it/s]\u001b[A\n",
      "Progress: 224.8it [00:46,  3.58it/s]                                                | 98.0/200 [00:16<00:22,  4.62it/s]\u001b[A\n",
      "Progress: 229.0it [00:48,  3.16it/s]█████████████▋                                 | 102.2/200 [00:18<00:25,  3.88it/s]\u001b[A\n",
      "Progress: 233.39999999999998it [00:51,  2.88it/s]██▏                               | 106.4/200 [00:20<00:27,  3.36it/s]\u001b[A\n",
      "Progress: 239.0it [00:53,  2.83it/s]             ████▏                             | 112.2/200 [00:22<00:27,  3.19it/s]\u001b[A\n",
      "Progress: 243.39999999999998it [00:55,  2.63it/s]█████▌                            | 116.4/200 [00:24<00:29,  2.82it/s]\u001b[A\n",
      "Progress: 247.59999999999997it [00:57,  2.46it/s]███████                           | 120.8/200 [00:26<00:30,  2.61it/s]\u001b[A\n",
      "Progress: 251.99999999999997it [00:59,  2.36it/s]████████▌                         | 125.0/200 [00:28<00:30,  2.44it/s]\u001b[A\n",
      "Progress: 256.19999999999993it [01:01,  2.28it/s]█████████▉                        | 129.4/200 [00:30<00:30,  2.35it/s]\u001b[A\n",
      "Progress: 260.5999999999999it [01:03,  2.24it/s] ███████████▍                      | 133.6/200 [00:33<00:29,  2.24it/s]\u001b[A\n",
      "Progress: 264.7999999999999it [01:05,  2.19it/s]██████████████▍                    | 139.4/200 [00:35<00:25,  2.41it/s]\u001b[A\n",
      "Progress:  71%|████████████████████████████████████████████████▎                   | 142.2/200 [00:37<00:27,  2.11it/s]\u001b[A\n",
      "\n",
      "Progress:   0%|                                                                                | 0/200 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Progress: 270.1999999999999it [01:13,  1.24it/s]                                    | 15.4/200 [00:04<00:48,  3.83it/s]\u001b[A\u001b[A\n",
      "Progress:  74%|██████████████████████████████████████████████████▏                 | 147.6/200 [00:45<00:43,  1.21it/s]\u001b[A\n",
      "\n",
      "Progress: 300.9999999999999it [01:15,  3.82it/s]                                    | 30.8/200 [00:06<00:31,  5.41it/s]\u001b[A\u001b[A\n",
      "Progress:  89%|████████████████████████████████████████████████████████████▋       | 178.4/200 [00:47<00:05,  3.78it/s]\u001b[A\n",
      "\n",
      "Progress: 316.39999999999986it [01:17,  4.61it/s]                                   | 46.2/200 [00:08<00:24,  6.24it/s]\u001b[A\u001b[A\n",
      "Progress:  97%|█████████████████████████████████████████████████████████████████▉  | 193.8/200 [00:49<00:01,  4.57it/s]\u001b[A\n",
      "\n",
      "Progress: 331.79999999999984it [01:19,  5.30it/s]                                   | 77.0/200 [00:10<00:13,  9.39it/s]\u001b[A\u001b[A\n",
      "Progress: 342.79999999999984it [01:21,  5.31it/s]                                                                      \u001b[A\n",
      "Progress: 220.20000000000002it [00:53,  5.29it/s]\u001b[A\n",
      "\n",
      "Progress: 346.99999999999983it [01:23,  4.43it/s]                                   | 89.4/200 [00:14<00:17,  6.19it/s]\u001b[A\u001b[A\n",
      "Progress: 224.40000000000003it [00:55,  4.42it/s]\u001b[A\n",
      "\n",
      "Progress: 351.1999999999998it [01:25,  3.78it/s]                                    | 93.6/200 [00:16<00:20,  5.11it/s]\u001b[A\u001b[A\n",
      "Progress: 230.20000000000005it [00:57,  3.99it/s]\u001b[A\n",
      "\n",
      "Progress: 355.5999999999998it [01:27,  3.31it/s]▊                                   | 98.0/200 [00:18<00:23,  4.28it/s]\u001b[A\u001b[A\n",
      "Progress: 234.40000000000003it [00:59,  3.46it/s]\u001b[A\n",
      "\n",
      "Progress: 359.7999999999998it [01:29,  2.95it/s]█▋                                 | 102.2/200 [00:20<00:26,  3.66it/s]\u001b[A\u001b[A\n",
      "Progress: 238.60000000000002it [01:01,  3.06it/s]\u001b[A\n",
      "\n",
      "Progress: 364.1999999999998it [01:31,  2.72it/s]███▏                               | 106.4/200 [00:22<00:29,  3.21it/s]\u001b[A\u001b[A\n",
      "Progress: 243.0it [01:03,  2.78it/s]             \u001b[A\n",
      "\n",
      "Progress: 369.79999999999984it [01:33,  2.71it/s]███▋                              | 110.8/200 [00:24<00:30,  2.90it/s]\u001b[A\u001b[A\n",
      "Progress: 247.2it [01:05,  2.55it/s]\u001b[A\n",
      "\n",
      "Progress: 374.1999999999998it [01:35,  2.55it/s] █████                             | 115.0/200 [00:26<00:32,  2.64it/s]\u001b[A\u001b[A\n",
      "Progress: 251.6it [01:07,  2.43it/s]\u001b[A\n",
      "\n",
      "Progress: 378.3999999999998it [01:38,  2.39it/s]███████▌                           | 119.4/200 [00:28<00:32,  2.50it/s]\u001b[A\u001b[A\n",
      "Progress: 255.79999999999998it [01:09,  2.32it/s]\u001b[A\n",
      "\n",
      "Progress: 382.79999999999984it [01:40,  2.32it/s]████████▌                         | 125.0/200 [00:30<00:29,  2.57it/s]\u001b[A\u001b[A\n",
      "Progress: 260.2it [01:11,  2.26it/s]             \u001b[A\n",
      "\n",
      "Progress: 386.99999999999983it [01:42,  2.23it/s]█████████▉                        | 129.4/200 [00:32<00:29,  2.43it/s]\u001b[A\u001b[A\n",
      "Progress: 264.4it [01:13,  2.18it/s]\u001b[A\n",
      "\n",
      "Progress: 391.1999999999998it [01:44,  2.17it/s] ███████████▍                      | 133.6/200 [00:34<00:28,  2.31it/s]\u001b[A\u001b[A\n",
      "Progress: 268.6it [01:16,  2.12it/s]\u001b[A\n",
      "\n",
      "Progress: 395.5999999999998it [01:46,  2.17it/s]█████████████▉                     | 138.0/200 [00:36<00:27,  2.25it/s]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#Data Extraction\n",
    "from youtube_comment_scraper_python import *\n",
    "import pandas as pd\n",
    "\n",
    "link=input(\"Youtube links: \")\n",
    "saved=input(\"Output name: \")\n",
    "youtube.open(link)\n",
    "\n",
    "response = youtube.video_comments()\n",
    "all_data=[]\n",
    "for i in range(0,2):   #It will scroll 2 times\n",
    "    response = youtube.video_comments()\n",
    "    data = response['body']\n",
    "    all_data.extend(data)\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(saved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a7698e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data Transformations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "#import functions for data preprocessing and data preparation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from string import punctuation\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a499987a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Roadmap -1. Learning a programmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am a data Science Student and believe me the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quality of Content shared above is simply ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steps to get in data ScienceStep 1 (3:32) : Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Roadmap -1. Learning a programmin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment\n",
       "0  Data Science Roadmap -1. Learning a programmin...\n",
       "1  I am a data Science Student and believe me the...\n",
       "2  The quality of Content shared above is simply ...\n",
       "3  Steps to get in data ScienceStep 1 (3:32) : Le...\n",
       "4  Data Science Roadmap -1. Learning a programmin..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Data\n",
    "df.columns\n",
    "data = pd.DataFrame(df['Comment'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be5ebcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\mamta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Compound</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Roadmap -1. Learning a programmin...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am a data Science Student and believe me the...</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quality of Content shared above is simply ...</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steps to get in data ScienceStep 1 (3:32) : Le...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Roadmap -1. Learning a programmin...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Positive  Negative  \\\n",
       "0  Data Science Roadmap -1. Learning a programmin...     0.000       0.0   \n",
       "1  I am a data Science Student and believe me the...     0.304       0.0   \n",
       "2  The quality of Content shared above is simply ...     0.193       0.0   \n",
       "3  Steps to get in data ScienceStep 1 (3:32) : Le...     0.000       0.0   \n",
       "4  Data Science Roadmap -1. Learning a programmin...     0.000       0.0   \n",
       "\n",
       "   Neutral  Compound Sentiment  \n",
       "0    1.000    0.0000   Neutral  \n",
       "1    0.696    0.8625  Positive  \n",
       "2    0.807    0.6705  Positive  \n",
       "3    1.000    0.0000   Neutral  \n",
       "4    1.000    0.0000   Neutral  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data labelling\n",
    "nltk.download('vader_lexicon')\n",
    "sentiments=SentimentIntensityAnalyzer()\n",
    "data[\"Positive\"] = [sentiments.polarity_scores(i)['pos'] for i in data['Comment']]\n",
    "data[\"Negative\"] = [sentiments.polarity_scores(i)['neg'] for i in data['Comment']]\n",
    "data[\"Neutral\"] = [sentiments.polarity_scores(i)['neu'] for i in data['Comment']]\n",
    "data[\"Compound\"] = [sentiments.polarity_scores(i)['compound'] for i in data['Comment']]\n",
    "score = data[\"Compound\"].values\n",
    "sentiment = []\n",
    "for i in score:\n",
    "    if i>=0.05:\n",
    "        sentiment.append('Positive')\n",
    "    elif i<=-0.05:\n",
    "        sentiment.append('Negative')\n",
    "    else: \n",
    "        sentiment.append(\"Neutral\")\n",
    "data[\"Sentiment\"] = sentiment\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec4f79e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Roadmap -1. Learning a programmin...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am a data Science Student and believe me the...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quality of Content shared above is simply ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steps to get in data ScienceStep 1 (3:32) : Le...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Roadmap -1. Learning a programmin...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Sentiment\n",
       "0  Data Science Roadmap -1. Learning a programmin...   Neutral\n",
       "1  I am a data Science Student and believe me the...  Positive\n",
       "2  The quality of Content shared above is simply ...  Positive\n",
       "3  Steps to get in data ScienceStep 1 (3:32) : Le...   Neutral\n",
       "4  Data Science Roadmap -1. Learning a programmin...   Neutral"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final data\n",
    "data2 = data.drop(['Positive','Negative','Neutral','Compound'],axis=1)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "770131f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data transformations\n",
    "stop_words = stopwords.words('english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "snowball_stemer = SnowballStemmer(language=\"english\")\n",
    "lzr = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ec5be87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n',' ',text)\n",
    "    text = re.sub('[%s]' % re.escape(punctuation),\"\",text)\n",
    "    text = re.sub(\"^a-zA-Z0-9$,.\",\"\",text)\n",
    "    text = re.sub(r'\\s+',' ',text,flags=re.I)\n",
    "    text = re.sub(r'\\W',' ',text)\n",
    "    text = ' '.join([word for word in word_tokenize(text) if word not in stop_words])\n",
    "    text = ' '.join([lzr.lemmatize(word) for word in word_tokenize(text)])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff05bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mamta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "data_copy = data2.copy()\n",
    "data_copy.Comment = data_copy.Comment.apply(lambda text: text_preprocessing(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5669de25",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data_copy['Sentiment'] = le.fit_transform(data_copy['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3566bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data science roadmap 1 learning programming la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data science student believe thing insight im ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>quality content shared simply eyeopener cheer ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>step get data sciencestep 1 332 learn pythonst...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data science roadmap 1 learning programming la...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment\n",
       "0  data science roadmap 1 learning programming la...          1\n",
       "1  data science student believe thing insight im ...          2\n",
       "2  quality content shared simply eyeopener cheer ...          2\n",
       "3  step get data sciencestep 1 332 learn pythonst...          1\n",
       "4  data science roadmap 1 learning programming la...          1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = {'sentence':data_copy.Comment,\n",
    "                  'sentiment':data_copy.Sentiment}\n",
    "processed_data = pd.DataFrame(processed_data)\n",
    "processed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "546169b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment\n",
       "2         32\n",
       "1          6\n",
       "0          2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame(processed_data['sentiment'].value_counts())\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d54c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balancing Data\n",
    "df_neutral = processed_data[(processed_data['sentiment']==1)]\n",
    "df_negative = processed_data[(processed_data['sentiment']==0)]\n",
    "df_positive=processed_data[(processed_data['sentiment']==2)]\n",
    "\n",
    "df_negative_unsampled = resample(df_negative,replace=True, n_samples=max(a['sentiment']), random_state=42)\n",
    "df_neutral_unsampled = resample(df_neutral,replace=True, n_samples=max(a['sentiment']), random_state=42)\n",
    "\n",
    "final_data = pd.concat([df_negative_unsampled,df_neutral_unsampled,df_positive])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5e2601d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32\n",
       "1    32\n",
       "2    32\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc05bce9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi video nothing knowledge love content bigdata intern want deep dive learn please make video bigdata engineering separately',\n",
       " 'informative video student new data science watching video confusion data science cleared thanx lot',\n",
       " 'hi video nothing knowledge love content bigdata intern want deep dive learn please make video bigdata engineering separately',\n",
       " 'hi video nothing knowledge love content bigdata intern want deep dive learn please make video bigdata engineering separately',\n",
       " 'hi video nothing knowledge love content bigdata intern want deep dive learn please make video bigdata engineering separately']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "for sentence in final_data['sentence']:\n",
    "    corpus.append(sentence)\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5b77837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = final_data.iloc[:,-1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e3be82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Machine learning model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75ebe608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0],\n",
       "       [ 0,  8,  0],\n",
       "       [ 0,  1,  9]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluation\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93bdd439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9655172413793104\n"
     ]
    }
   ],
   "source": [
    "nb_score = accuracy_score(y_test,y_pred)\n",
    "print('accuracy',nb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8799308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(classifier,open('model.pkl','wb'))\n",
    "model = pickle.load(open('model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2120b8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 2, 2, 0, 2, 1, 1, 1, 2, 2, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 2, 1, 1, 0, 2, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6baff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
